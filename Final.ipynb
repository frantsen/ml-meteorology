{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Science 358: Independent Research / Machine Learning for Meteorology\n",
    "_Rachel Frantsen '16, Dr. Matthew Richey_\n",
    "\n",
    "The following program is the result of experimentation with the application of machine learning (ML) techniques to meteorological radar. Currently, numerical weather prediction (NWP) is the dominant technique for predicting weather patterns, employing mathematical models based on fluid dynamics and thermodynamics. Investigations into meteorological applications of ML have been few and far between, due to ML's recent emergence as a potentially useful tool.\n",
    "\n",
    "Current NWP models are effective thanks to decades of development when there was no feasible alternative, and ML approaches may need the same attention and development in order to become competitively useful - however we will never know unless we take the time to develop the techniques.\n",
    "\n",
    "This independent research seeks to investigate the potential of ML techniques in meteorological applications and develop a framework for asking questions about its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiving data from NOAA\n",
    "\n",
    "I tried out several sources of weather data and techniques for fetching them - including Weather Underground, the National Oceanic and Atmospheric Administration's (NOAA) Climate Data archives, and the NOAA radar system. Wunderground provided a convenient API for accessing weather information such as temperature and rainfall amount at particular observation sites, but it was more difficult to recieve radar. The Climate Data archives provided a large amount of data in bulk, but it was inconvenient to obtain and to parse. My work with NOAA radar was most productive so that is what is used in this demonstration.\n",
    "\n",
    "In order to retrieve the data, I set up a scheduled job using Cron on a lab computer to run the following script every three hours, since it took about three hours on average to run the script each time and there was about only about four recent hours of data available online at a time.\n",
    "\n",
    "As evident in the script, I pulled six typs of radar from 16 radar stations from the inland United States, varying the time between each download in order to limit the load on the NOAA servers, and then logged the time the download was completed. At the time of my writing this, there had been a total of 481 full downloads. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "base_dir=/project/frantsen\n",
    "\n",
    "for station in MPX FSD MVX DMX ABR DVN OAX DLX MBX GGW BIS TWX EAX LSX VWX ILX\n",
    "do\n",
    "  for type in N0R N0S N1P NCR NTP N0V\n",
    "  do\n",
    "    wget -N -P $base_dir/radar_archive -r -l 1 --no-parent -w 5 --random-wait https://radar.weather.gov/ridge/RadarImg/$type/$station -A \"*.gif\" -R \"*_0.gif\"\n",
    "  done\n",
    "done\n",
    "\n",
    "echo \"Download completed at\" $(date -u) >> $base_dir/radar_archive/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_After recieving data from NOAA onto RNS 202-20, I loaded them onto my local machine to use on the Jupyter Ipython 3.6 server that I set up there, using an rsync command._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to data\n",
    "\n",
    "The following cell is a function (translate_n0r) that converts a N0R or N0S radar image to a list of dBZ values.\n",
    "\n",
    "> \"dBZ\" stands for decibels relative to _Z_, a factor of reflectivity relative to that of a 1 mm drop of rain. The abbreviation can be thought of simply as _reflectivity_, and it directly corresponds to a specific intensity in precipitation. For example, 10 dBZ directly corresponds to light mist, and 50 dBZ corresponds to heavy rain.\n",
    "\n",
    "The function gets RGB values from the palette of the GIF-formatted radar image, then uses a dictionary to translate the RGB values into single dBZ data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate_n0r(img, palette):\n",
    "    standardizedImg = []\n",
    "    known_colors = {(0, 142, 0): 30,\n",
    "     (1, 159, 244): 10,\n",
    "     (1, 197, 1): 25,\n",
    "     (2, 253, 2): 20,\n",
    "     (3, 0, 244): 15,\n",
    "     (4, 233, 231): 5,\n",
    "     (152, 84, 198): 70,\n",
    "     (212, 0, 0): 55,\n",
    "     (229, 188, 0): 40,\n",
    "     (248, 0, 253): 65,\n",
    "     (253, 0, 0): 50,\n",
    "     (253, 149, 0): 45,\n",
    "     (253, 248, 2): 35,\n",
    "     (253, 253, 253): 75}\n",
    "    for j in range(len(img)):\n",
    "        colorNum = img[j]\n",
    "        r,g,b = palette[colorNum*3+0], palette[colorNum*3+1], palette[colorNum*3+2]\n",
    "        if (r,g,b) in known_colors:\n",
    "            standardizedImg.append(known_colors[(r,g,b)])\n",
    "        else:\n",
    "            standardizedImg.append(0)\n",
    "    return standardizedImg         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data from the file system\n",
    "\n",
    "The following function reads in files from my local radar repository and outputs two multidimensional Python arrays - one which is the input data for training, and one which is the predicted result for that data. There are multiple rows in each, depending on the \"num_samples\" paramter. Along the way, we resize each image, in order to reduce the number of pixels we must create models for.\n",
    "\n",
    "Note that while our objective is to train ML models, one for each pixel, I am using the entire image to train each pixel. The hope is that the motion of the weather nearby will contribute to the prediction of each individual spot. This is an attempt to avoid the problems that I ran into when trying to predict temperature data by using data from only one observation station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_data(locations, radar_type, sample_size, num_samples_initial, frame_delay=0, dimension=20):\n",
    "    X_output = []  \n",
    "    to_Y = []\n",
    "    for location in locations:\n",
    "        cur_path = \"../radar_archive/radar.weather.gov/ridge/RadarImg/\"+radar_type+\"/\"+location\n",
    "        all_files = os.listdir(cur_path)[1:]\n",
    "        num_samples = min(num_samples_initial, len(all_files)-sample_size-frame_delay-1)\n",
    "        for i in range(num_samples):\n",
    "            files_subset = all_files[i:sample_size+i+frame_delay+1]\n",
    "            to_output = []\n",
    "            for filename in files_subset:\n",
    "                infileName = cur_path+\"/\"+filename\n",
    "                outfileName = cur_path+\"/small/\"+filename\n",
    "                im = Image.open(infileName)\n",
    "                im = im.resize((dimension,dimension))\n",
    "                to_output.extend(translate_n0r(list(im.getdata()), im.getpalette()))\n",
    "                im.save(outfileName, \"gif\")\n",
    "            to_Y.append(to_output[-dimension**2:])\n",
    "            X_output.append(to_output[:-((dimension**2)*(1+frame_delay))])\n",
    "    \n",
    "    # Rotate Y data\n",
    "    Y_output = []  \n",
    "    for i in range(dimension**2):\n",
    "        short_Y = []\n",
    "        for j in range(num_samples*len(locations)):\n",
    "            short_Y.append(to_Y[j][i])\n",
    "        Y_output.append(short_Y)\n",
    "    \n",
    "    return X_output, Y_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_dataframe, Y_file_vals = import_data([\"BIS\", \"TWX\", \"EAX\"], \"N0R\", 30, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I transformed the data into a Pandas dataframe so that it would be compatible with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0:1,1</th>\n",
       "      <th>0:1,2</th>\n",
       "      <th>0:1,3</th>\n",
       "      <th>0:1,4</th>\n",
       "      <th>0:1,5</th>\n",
       "      <th>0:1,6</th>\n",
       "      <th>0:1,7</th>\n",
       "      <th>0:1,8</th>\n",
       "      <th>0:1,9</th>\n",
       "      <th>0:1,10</th>\n",
       "      <th>...</th>\n",
       "      <th>29:20,11</th>\n",
       "      <th>29:20,12</th>\n",
       "      <th>29:20,13</th>\n",
       "      <th>29:20,14</th>\n",
       "      <th>29:20,15</th>\n",
       "      <th>29:20,16</th>\n",
       "      <th>29:20,17</th>\n",
       "      <th>29:20,18</th>\n",
       "      <th>29:20,19</th>\n",
       "      <th>29:20,20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0:1,1  0:1,2  0:1,3  0:1,4  0:1,5  0:1,6  0:1,7  0:1,8  0:1,9  0:1,10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "2      0      0      0      0      0      0      0      0      0       0   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "4      0      0      0      0      0      0      0      0      0       0   \n",
       "5      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "     ...     29:20,11  29:20,12  29:20,13  29:20,14  29:20,15  29:20,16  \\\n",
       "0    ...            0         0         0         0         0         0   \n",
       "1    ...            0         0         0         0         0         0   \n",
       "2    ...            0         0         0         0         0         0   \n",
       "3    ...            0         0         0         0         0         0   \n",
       "4    ...            0         0         0         0         0         0   \n",
       "5    ...            0         0         0         0         0         0   \n",
       "\n",
       "   29:20,17  29:20,18  29:20,19  29:20,20  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "\n",
       "[6 rows x 12000 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels for the data\n",
    "df_columns = []\n",
    "for i in range(30):\n",
    "    for j in range(20):\n",
    "        for k in range(20):\n",
    "            df_columns.append(str(i)+\":\"+str(j+1)+\",\"+str(k+1))\n",
    "            \n",
    "# Convert to Pandas dataframe\n",
    "df = pd.DataFrame(to_dataframe, columns=df_columns)\n",
    "df = df._get_numeric_data()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the prediction\n",
    "\n",
    "Here I created an array of models, and each model represents one pixel in an image. Again for each row of the table I am using an array of data from whole images, in this case 30 images, to predict each single pixel.\n",
    "\n",
    "**WARNING: This cell may take a VERY long time to run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_models = []\n",
    "for i in range(20**2):\n",
    "    Y_train_pixel = pd.DataFrame(Y_file_vals[i])\n",
    "    pixel_models.append(Lasso(alpha=100).fit(df, Y_train_pixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0:1,1</th>\n",
       "      <th>0:1,2</th>\n",
       "      <th>0:1,3</th>\n",
       "      <th>0:1,4</th>\n",
       "      <th>0:1,5</th>\n",
       "      <th>0:1,6</th>\n",
       "      <th>0:1,7</th>\n",
       "      <th>0:1,8</th>\n",
       "      <th>0:1,9</th>\n",
       "      <th>0:1,10</th>\n",
       "      <th>...</th>\n",
       "      <th>29:20,11</th>\n",
       "      <th>29:20,12</th>\n",
       "      <th>29:20,13</th>\n",
       "      <th>29:20,14</th>\n",
       "      <th>29:20,15</th>\n",
       "      <th>29:20,16</th>\n",
       "      <th>29:20,17</th>\n",
       "      <th>29:20,18</th>\n",
       "      <th>29:20,19</th>\n",
       "      <th>29:20,20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0:1,1  0:1,2  0:1,3  0:1,4  0:1,5  0:1,6  0:1,7  0:1,8  0:1,9  0:1,10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "     ...     29:20,11  29:20,12  29:20,13  29:20,14  29:20,15  29:20,16  \\\n",
       "0    ...            0         0         0         0         0         0   \n",
       "\n",
       "   29:20,17  29:20,18  29:20,19  29:20,20  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 12000 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, Y_test = import_data([\"ILX\"], \"N0R\", 30, 1)\n",
    "df_test = pd.DataFrame(X_test, columns=df_columns)\n",
    "df_test = df_test._get_numeric_data()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_radar = []\n",
    "for i in range(20**2):\n",
    "    predicted_pixel_Y = pixel_models[i].predict(df)\n",
    "    predicted_radar.append(int(predicted_pixel_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning predicted data back into an image\n",
    "\n",
    "The function save_predicted turns the predicted data into an easily understood visual format, a GIF file just like all the input data. It does this by mapping each predicted value onto a tuple that represents an RGB value, and then saves it as a new image in a designated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_predicted(predicted_values, d, newfilename):\n",
    "    n0r_to_color = {5: (4, 233, 231, 1),\n",
    "     10: (1, 159, 244, 1),\n",
    "     15: (3, 0, 244, 1),\n",
    "     20: (2, 253, 2, 1),\n",
    "     25: (1, 197, 1, 1),\n",
    "     30: (0, 142, 0, 1),\n",
    "     35: (253, 248, 2, 1),\n",
    "     40: (229, 188, 0, 1),\n",
    "     45: (253, 149, 0, 1),\n",
    "     50: (253, 0, 0, 1),\n",
    "     55: (212, 0, 0, 1),\n",
    "     65: (248, 0, 253, 1),\n",
    "     70: (152, 84, 198, 1),\n",
    "     75: (253, 253, 253, 1),\n",
    "     0: (0,0,0,0)}\n",
    "    rgba_image_array = []\n",
    "    for value in predicted_values:\n",
    "        rgba_image_array.append(n0r_to_color[value-value%5])\n",
    "    img = Image.new(\"RGBA\", (d, d), color = (0,0,0,0))\n",
    "    img.putdata(rgba_image_array)\n",
    "    img.save(newfilename, transparent = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_filenames = [\"N0R_ILX_1\"]\n",
    "predicted_filepaths = []\n",
    "for predicted_filename in predicted_filenames:\n",
    "    predicted_filepath = \"../radar_predicted/\" + predicted_filename + \".gif\"\n",
    "    predicted_filepaths += [predicted_filepath]\n",
    "    save_predicted(predicted_radar, 20, predicted_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image example\n",
    "\n",
    "Here I've compared a predicted image, using models trained over four iterations, with the actual image corresponding with the test dataset, for purposes of illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Predicted N0R at ILX: <img src=\"../radar_predicted/N0R_ILX_1.gif\" width=50% height=50% style=\"image-rendering:pixelated\"><br>Actual N0R at ILX: <img src=\"../radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ILX/small/ILX_20170414_0234_N0R.gif\" width=50% height=50% style=\"image-rendering:pixelated\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayMarkup = 'Predicted {} at {}: <img src=\"{}\" width=50% height=50% style=\"image-rendering:pixelated\">'.format(\"N0R\", \"ILX\", predicted_filepaths[0])\n",
    "Y_test_filepath = \"../radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ILX/small/\" + os.listdir(\"../radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ILX\")[30]\n",
    "displayMarkup += '<br>Actual {} at {}: <img src=\"{}\" width=50% height=50% style=\"image-rendering:pixelated\">'.format(\"N0R\", \"ILX\", Y_test_filepath)\n",
    "display.HTML(displayMarkup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring accuracy\n",
    "\n",
    "To create a measure of accuracy the following function calculates both Mean Squared Error (MSE) and Euclidian Error. (In the first few \"proof of concept\" cells, we examine both MSE and Euclidian Error, but for use in practice we use exclusively Euclidian Error.)\n",
    "\n",
    "It is worth mentioning that the error rates are calculated by the difference of dBZ values at original(x,y) and predicted(x,y). I.e., different values at the same location. This could prove problematic when the prediction is pretty close, but perhaps one pixel is off by a column or row. In this case, the difference would be counted twice - once for being missing from the correct spot, and once for being present in an incorrect spot. Visualize with me an extreme case of this - the expected result is a checkerboard with an even number of columns, but the predicted result is the same checkerboard flipped across the Y axis. At first glance the prediction looks very impressive, and in fact it is in the overall scheme. However because of the specificities of the error calculation method this case would yield a very high error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mse_euclidian_error(predicted, calculated):\n",
    "    from math import sqrt\n",
    "    squared_total_vals = 0.0\n",
    "    length = len(calculated)\n",
    "    for i in range(length):\n",
    "        squared_total_vals += (predicted[i] - calculated[i])**2\n",
    "    mse = squared_total_vals/length\n",
    "    euclidian_distance = sqrt(squared_total_vals)/length\n",
    "    return mse, euclidian_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the MSE and Euclidian Error rates of the last (visual) example - the predicted frame versus the actual next frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5.285, 0.11494563932572649)\n"
     ]
    }
   ],
   "source": [
    "im = Image.open(Y_test_filepath)\n",
    "Y_file_vals = translate_n0r(list(im.getdata()), im.getpalette())\n",
    "print(mse_euclidian_error(Y_file_vals, predicted_radar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: the error rate of the \"null case\" - the error rate of the frame to be predicted as compared to the frame directly before it (used in the training set). It is evident that the prediction model is doing a better job than predicting a frame that is exactly the same as the previous one. This is the result we hoped for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0 0.25495097567963926\n"
     ]
    }
   ],
   "source": [
    "previous_Y_filepath = \"../radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ILX/small/\" + os.listdir(\"../radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ILX\")[29]\n",
    "im_prev = Image.open(previous_Y_filepath)\n",
    "Y_prev_vals = translate_n0r(list(im_prev.getdata()), im_prev.getpalette())\n",
    "mse2, euc2 = mse_euclidian_error(Y_file_vals, Y_prev_vals)\n",
    "print(mse2, euc2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest error rate can be seen below, demonstrated as a comparison between two identical arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(mse_euclidian_error(Y_file_vals, Y_file_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below: a high error rate generated by comparing two randomly-generated arrays of the same size as our 20-by-20 scaled-down radar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(936.9275, 1.5304635735619454)\n"
     ]
    }
   ],
   "source": [
    "random_1 = []\n",
    "random_2 = []\n",
    "for i in range(400):\n",
    "    random_1.append(random.randrange(0,76))\n",
    "    random_2.append(random.randrange(0,76))\n",
    "print(mse_euclidian_error(random_1, random_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing results of different training set sizes\n",
    "\n",
    "The function error_from_num_iterations is all the code we have demonstrated so far collected to return an error rate. The parameter num_iterations specifies the number of rows from each of the stations MPX, DMX, ABR, OAX, and ILX to use in model training. The example below compares the accuracy of five total rows versus ten. It is a small amount, but I felt that I would need greater computing power to be able to scale this very much further.\n",
    "\n",
    "**WARNING: THE SECOND CELL FOLLOWING ALWAYS AN TAKES EXTREMELY LONG TIME TO RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_from_num_iterations_and_delay(num_iterations, saveas, delay=0, model=0):\n",
    "    to_dataframe, Y_file_vals = import_data([\"BIS\", \"DMX\", \"DVN\", \"EAX\", \"TWX\"], \"N0R\", 30, num_iterations, frame_delay = delay)\n",
    "\n",
    "    # Create labels for the data\n",
    "    df_columns = []\n",
    "    for i in range(30):\n",
    "        for j in range(20):\n",
    "            for k in range(20):\n",
    "                df_columns.append(str(i)+\":\"+str(j+1)+\",\"+str(k+1))\n",
    "\n",
    "    # Convert to Pandas dataframe\n",
    "    df = pd.DataFrame(to_dataframe, columns=df_columns)\n",
    "    df = df._get_numeric_data()\n",
    "\n",
    "    # Train pixel models\n",
    "    pixel_models = []\n",
    "    for i in range(20**2):\n",
    "        Y_train_pixel = pd.DataFrame(Y_file_vals[i])\n",
    "        if model == 0:\n",
    "            pixel_models.append(Lasso(alpha=100).fit(df, Y_train_pixel))\n",
    "        elif model == 1:\n",
    "            pixel_models.append(Ridge(alpha=100).fit(df, Y_train_pixel))\n",
    "\n",
    "    X_test, Y_test = import_data([\"ILX\"], \"N0R\", 30, 1)\n",
    "    df_test = pd.DataFrame(X_test, columns=df_columns)\n",
    "    df_test = df_test._get_numeric_data()\n",
    "\n",
    "    predicted_radar = []\n",
    "    for i in range(20**2):\n",
    "        predicted_pixel_Y = pixel_models[i].predict(df)\n",
    "        predicted_radar.append(int(predicted_pixel_Y[0]))\n",
    "\n",
    "    predicted_filepath = \"../radar_predicted/\" + saveas + \".gif\"\n",
    "    save_predicted(predicted_radar, 20, predicted_filepath)\n",
    "\n",
    "    im = Image.open(Y_test_filepath)\n",
    "    Y_file_vals = translate_n0r(list(im.getdata()), im.getpalette())\n",
    "    mse, euc = mse_euclidian_error(Y_file_vals, predicted_radar)\n",
    "    return euc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error_by_iterations = []\n",
    "# Warning: the number of rows you enter as the range will be multiplied by 5! 1 is not a small difference!\n",
    "for i in [1, 2, 4, 6]:\n",
    "    ls = []\n",
    "    ls.append(i)\n",
    "    filename = \"N0R_ILX_bulk_\" + str(i)\n",
    "    ls.append(error_from_num_iterations_and_delay(i, filename, 0))\n",
    "    error_by_iterations.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.10479145957567343],\n",
       " [2, 0.10550473923004595],\n",
       " [4, 0.09575359001102779],\n",
       " [6, 0.09585144756340407]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_by_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaton of error rates\n",
    "\n",
    "According to the visualization below, it is easy to see that the error rates of the prediction are decreasing (overall) even over elementary increases to the size of the training set. With even more computing power we would be able to see a greater increase in accuracy. Here we increase the training set from 5, to 10, to 15, to 20, since the set of training material consists of five stations and we increase the number of samples of each by 1.\n",
    "\n",
    "In this case, the number of samples, or \"iteration number\", uses the same 5 stations as in previous examples, but also a number of sets \"shifted over\" by one. It is simply a convenient way to increase the size of the set of training data. So if we have frames 1,2,3,4,5,6 for each station, specifying an iteration number of 3 would give {x}{y} training sets of {1,2,3}{4}, {2,3,4}{5}, {3,4,5},{6}. You can see this code in action in the function under \"Pulling data from the file system\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb586c90b38>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb5831bcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_x = []\n",
    "plot_y = []\n",
    "for i in range(len(error_by_iterations)):\n",
    "    plot_x.append(error_by_iterations[i][0])\n",
    "    plot_y.append(error_by_iterations[i][1])\n",
    "        \n",
    "plot_x = np.array(plot_x)\n",
    "plot_y = np.array(plot_y)\n",
    "plt.scatter(plot_x, plot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error over different prediction intervals\n",
    "\n",
    "The following code tries different \"delay\" values - or the number of frames in the future to predict. By this I mean if we have frames 1,2,3,4,5,6,7,8 to work with and we always train on 1,2,3,4, a delay of 1 would mean we train our models to predict frame 5, a delay of 2 would mean we're trying to predict frame 6, etc. Since there are anywhere between 10-12 frames recorded per hour and roughly 5 minutes between each frame, a delay of 10 frames is about equivalent to an hour. So I've tested the accuracy of our model (using 5 training iterations) over prediction intervals of 0, about 10 minutes, 20 minutes, 30 minutes... up to an hour.\n",
    "\n",
    "Below you can also see this increase plotted on a graph to visualize the rate at which the accuracy decreases with further intervals. The data varies, but there is a clear _overall_ downward trend, and it seems not to be very steep - the difference. Here, the difference between predicting the next frame has a similar error rate to predicting the state of precipitation in 45 minutes.\n",
    "\n",
    "**WARNING: THE FOLLOWING CELL TAKES AN EXTREMELY LONG TIME TO RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb586ef9748>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nByGIxgUYU7tHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb58764abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_by_distance_in_future = []\n",
    "# Warning: the number of rows you enter as the range will be multiplied by 5! 1 is not a small difference!\n",
    "for i in [0,2,4,6,8,10]:\n",
    "    ls = []\n",
    "    ls.append(i)\n",
    "    filename = \"N0R_ILX_delay_\" + str(i)\n",
    "    ls.append(error_from_num_iterations_and_delay(4, filename, i)) # 20 rows of training data for each test sample\n",
    "    error_by_distance_in_future.append(ls)\n",
    "error_by_distance_in_future\n",
    "\n",
    "plot2_x = []\n",
    "plot2_y = []\n",
    "for i in range(len(error_by_distance_in_future)):\n",
    "    plot2_x.append(error_by_distance_in_future[i][0])\n",
    "    plot2_y.append(error_by_distance_in_future[i][1])\n",
    "        \n",
    "plot2_x = np.array(plot2_x)\n",
    "plot2_y = np.array(plot2_y)\n",
    "plt.scatter(plot2_x, plot2_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectiveness of other predicive models\n",
    "\n",
    "In the following cell we try ridge regression using the same training/test data as in the visual (first) example. There is an even better error rate using ridge regression than we got using lasso (~0.115...)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10350120772242226\n"
     ]
    }
   ],
   "source": [
    "print(error_from_num_iterations_and_delay(i, \"N0R_ILX_ridge_\", 0, model = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and future work\n",
    "\n",
    "Over the course of this project I found that larger training sizes actually did improve the predictive ability of the model we used, and the decrease in accuracy over larger prediction intervals was not as steep of a curve as I expected to see!\n",
    "\n",
    "The main constraint on this research effort was the very same issue that hampers NWP prediction techniques at large scale - the availability of computing power. Moving to an Amazon Web Service (AWS) virtual machine may be an open door to experiment with exactly that. Currently, this notebook is operating on a Micro T2 instance of Elastic Cloud 2, which provides 1 virtual CPU and 1 GB of memory. Detaching the storage volume from this instance and reattaching it to a more powerful one, if we choose to exceed the free account teir, would be fairly straightforward. Future efforts might include an increase of computing power, as well as parallel and distributed techniques, to extend the capability of meteorological ML applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
