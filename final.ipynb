{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Science 358: Independent Research / Machine Learning for Meteorology\n",
    "_Rachel Frantsen, 2016, and Dr. Matthew Richey_\n",
    "\n",
    "The following program is the result of experimentation with the application of machine learning (ML) techniques to meteorological radar. Currently, numerical weather prediction (NWP) is the dominant technique for predicting weather patterns, employing mathematical models based on fluid dynamics and thermodynamics. Investigations into meteorological applications of ML have been few and far between, due to ML's recent emergence as a potentially useful tool.\n",
    "\n",
    "Current NWP models are effective thanks to decades of development when there was no feasible alternative, and ML approaches may need the same attention and development in order to become competitively useful - however we will never know unless we take the time to develop the techniques.\n",
    "\n",
    "This independent research seeks to investigate the potential of ML techniques in meteorological applications and develop a framework for asking questions about its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiving data from NOAA\n",
    "\n",
    "I tried out several sources of weather data and techniques for fetching them - including Weather Underground, the National Oceanic and Atmospheric Administration's (NOAA) Climate Data archives, and the NOAA radar system. Wunderground provided a convenient API for accessing weather information such as temperature and rainfall amount at particular observation sites, but it was more difficult to recieve radar. The Climate Data archives provided a large amount of data in bulk, but it was inconvenient to obtain and to parse. My work with NOAA radar was most productive so that is what is used in this demonstration.\n",
    "\n",
    "In order to retrieve the data, I set up a scheduled job using Cron on a lab computer to run the following script every three hours, since it took about three hours on average to run the script each time and there was about only about four recent hours of data available online at a time.\n",
    "\n",
    "As evident in the script, I pulled six typs of radar from 16 radar stations from the inland United States, varying the time between each download in order to limit the load on the NOAA servers, and then logged the time the download was completed. At the time of my writing this, there had been a total of 481 full downloads. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "\n",
    "base_dir=/project/frantsen\n",
    "\n",
    "for station in MPX FSD MVX DMX ABR DVN OAX DLX MBX GGW BIS TWX EAX LSX VWX ILX\n",
    "do\n",
    "  for type in N0R N0S N1P NCR NTP N0V\n",
    "  do\n",
    "    wget -N -P $base_dir/radar_archive -r -l 1 --no-parent -w 5 --random-wait https://radar.weather.gov/ridge/RadarImg/$type/$station -A \"*.gif\" -R \"*_0.gif\"\n",
    "  done\n",
    "done\n",
    "\n",
    "echo \"Download completed at\" $(date -u) >> $base_dir/radar_archive/log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_After recieving data from NOAA onto RNS 202-20, I loaded them onto my local machine to use on the Jupyter Ipython 3.6 server that I set up there, using an rsync command._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to data\n",
    "\n",
    "The following cell is a function (translate_n0r) that converts a N0R or N0S radar image to a list of dBZ values.\n",
    "\n",
    "> \"dBZ\" stands for decibels relative to _Z_, a factor of reflectivity relative to that of a 1 mm drop of rain. The abbreviation can be thought of simply as _reflectivity_, and it directly corresponds to a specific intensity in precipitation. For example, 10 dBZ directly corresponds to light mist, and 50 dBZ corresponds to heavy rain.\n",
    "\n",
    "The function gets RGB values from the palette of the GIF-formatted radar image, then uses a dictionary to translate the RGB values into single dBZ data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate_n0r(img, palette):\n",
    "    standardizedImg = []\n",
    "    known_colors = {(0, 142, 0): 30,\n",
    "     (1, 159, 244): 10,\n",
    "     (1, 197, 1): 25,\n",
    "     (2, 253, 2): 20,\n",
    "     (3, 0, 244): 15,\n",
    "     (4, 233, 231): 5,\n",
    "     (152, 84, 198): 70,\n",
    "     (212, 0, 0): 55,\n",
    "     (229, 188, 0): 40,\n",
    "     (248, 0, 253): 65,\n",
    "     (253, 0, 0): 50,\n",
    "     (253, 149, 0): 45,\n",
    "     (253, 248, 2): 35,\n",
    "     (253, 253, 253): 75}\n",
    "    for j in range(len(img)):\n",
    "        colorNum = img[j]\n",
    "        r,g,b = palette[colorNum*3+0], palette[colorNum*3+1], palette[colorNum*3+2]\n",
    "        if (r,g,b) in known_colors:\n",
    "            standardizedImg.append(known_colors[(r,g,b)])\n",
    "        else:\n",
    "            standardizedImg.append(0)\n",
    "    return standardizedImg         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data from the file system\n",
    "\n",
    "The following function reads in files from my local radar repository and outputs two multidimensional Python arrays - one which is the input data for training, and one which is the predicted result for that data. There are multiple rows in each, depending on the \"num_samples\" paramter. Along the way, we resize each image, in order to reduce the number of pixels we must create models for.\n",
    "\n",
    "Note that while our objective is to train ML models, one for each pixel, I am using the entire image to train each pixel. The hope is that the motion of the weather nearby will contribute to the prediction of each individual spot. This is an attempt to avoid the problems that I ran into when trying to predict temperature data by using data from only one observation station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def import_data(locations, radar_type, sample_size, num_samples_initial, frame_delay=0, dimension=20):\n",
    "    X_output = []  \n",
    "    to_Y = []\n",
    "    for location in locations:\n",
    "        cur_path = \"radar_archive/radar.weather.gov/ridge/RadarImg/\"+radar_type+\"/\"+location\n",
    "        all_files = os.listdir(cur_path)[1:]\n",
    "        num_samples = min(num_samples_initial, len(all_files)-sample_size-frame_delay-1)\n",
    "        for i in range(num_samples):\n",
    "            files_subset = all_files[i:sample_size+i+1]\n",
    "            to_output = []\n",
    "            for filename in files_subset:\n",
    "                infileName = cur_path+\"/\"+filename\n",
    "                outfileName = cur_path+\"/small/\"+filename\n",
    "                im = Image.open(infileName)\n",
    "                im = im.resize((dimension,dimension))\n",
    "                to_output.extend(translate_n0r(list(im.getdata()), im.getpalette()))\n",
    "                im.save(outfileName, \"gif\")\n",
    "            to_Y.append(to_output[-dimension**2:])\n",
    "            X_output.append(to_output[:-dimension**2])\n",
    "    \n",
    "    # Rotate Y data\n",
    "    Y_output = []  \n",
    "    for i in range(dimension**2):\n",
    "        short_Y = []\n",
    "        for j in range(num_samples*len(locations)):\n",
    "            short_Y.append(to_Y[j][i])\n",
    "        Y_output.append(short_Y)\n",
    "    \n",
    "    return X_output, Y_output\n",
    " \n",
    "to_dataframe, Y_file_vals = import_data([\"MPX\", \"DMX\"], \"N0R\", 30, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I transformed the data into a Pandas dataframe so that it would be compatible with Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0:1,1</th>\n",
       "      <th>0:1,2</th>\n",
       "      <th>0:1,3</th>\n",
       "      <th>0:1,4</th>\n",
       "      <th>0:1,5</th>\n",
       "      <th>0:1,6</th>\n",
       "      <th>0:1,7</th>\n",
       "      <th>0:1,8</th>\n",
       "      <th>0:1,9</th>\n",
       "      <th>0:1,10</th>\n",
       "      <th>...</th>\n",
       "      <th>29:20,11</th>\n",
       "      <th>29:20,12</th>\n",
       "      <th>29:20,13</th>\n",
       "      <th>29:20,14</th>\n",
       "      <th>29:20,15</th>\n",
       "      <th>29:20,16</th>\n",
       "      <th>29:20,17</th>\n",
       "      <th>29:20,18</th>\n",
       "      <th>29:20,19</th>\n",
       "      <th>29:20,20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0:1,1  0:1,2  0:1,3  0:1,4  0:1,5  0:1,6  0:1,7  0:1,8  0:1,9  0:1,10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "1      0      0      0      0      0      0      0      0      0       0   \n",
       "2      0      0      0      0      0      0      0      0      0       0   \n",
       "3      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "     ...     29:20,11  29:20,12  29:20,13  29:20,14  29:20,15  29:20,16  \\\n",
       "0    ...            0         0         0         0         0         0   \n",
       "1    ...            0         0         0         0         0         0   \n",
       "2    ...            0         0         0         0         0         0   \n",
       "3    ...            0         0         0         0         0         0   \n",
       "\n",
       "   29:20,17  29:20,18  29:20,19  29:20,20  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "\n",
       "[4 rows x 12000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create labels for the data\n",
    "df_columns = []\n",
    "for i in range(30):\n",
    "    for j in range(20):\n",
    "        for k in range(20):\n",
    "            df_columns.append(str(i)+\":\"+str(j+1)+\",\"+str(k+1))\n",
    "            \n",
    "# Convert to Pandas dataframe\n",
    "df = pd.DataFrame(to_dataframe, columns=df_columns)\n",
    "df = df._get_numeric_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the prediction\n",
    "\n",
    "Here I created an array of models, and each model represents one pixel in an image. Again for each row of the table I am using an array of data from whole images, in this case 30 images, to predict each single pixel.\n",
    "\n",
    "**WARNING: This cell may take a VERY long time to run!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_models = []\n",
    "for i in range(20**2):\n",
    "    Y_train_pixel = pd.DataFrame(Y_file_vals[i])\n",
    "    pixel_models.append(Lasso(alpha=100).fit(df, Y_train_pixel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0:1,1</th>\n",
       "      <th>0:1,2</th>\n",
       "      <th>0:1,3</th>\n",
       "      <th>0:1,4</th>\n",
       "      <th>0:1,5</th>\n",
       "      <th>0:1,6</th>\n",
       "      <th>0:1,7</th>\n",
       "      <th>0:1,8</th>\n",
       "      <th>0:1,9</th>\n",
       "      <th>0:1,10</th>\n",
       "      <th>...</th>\n",
       "      <th>29:20,11</th>\n",
       "      <th>29:20,12</th>\n",
       "      <th>29:20,13</th>\n",
       "      <th>29:20,14</th>\n",
       "      <th>29:20,15</th>\n",
       "      <th>29:20,16</th>\n",
       "      <th>29:20,17</th>\n",
       "      <th>29:20,18</th>\n",
       "      <th>29:20,19</th>\n",
       "      <th>29:20,20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 12000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0:1,1  0:1,2  0:1,3  0:1,4  0:1,5  0:1,6  0:1,7  0:1,8  0:1,9  0:1,10  \\\n",
       "0      0      0      0      0      0      0      0      0      0       0   \n",
       "\n",
       "     ...     29:20,11  29:20,12  29:20,13  29:20,14  29:20,15  29:20,16  \\\n",
       "0    ...            0         0         0         0         0         0   \n",
       "\n",
       "   29:20,17  29:20,18  29:20,19  29:20,20  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 12000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, Y_test = import_data([\"ABR\"], \"N0R\", 30, 1)\n",
    "df_test = pd.DataFrame(X_test, columns=df_columns)\n",
    "df_test = df_test._get_numeric_data()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_radar = []\n",
    "for i in range(20**2):\n",
    "    predicted_pixel_Y = pixel_models[i].predict(df)\n",
    "    predicted_radar.append(int(predicted_pixel_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning predicted data back into an image\n",
    "\n",
    "The function save_predicted turns the predicted data into an easily understood visual format, a GIF file just like all the input data. It does this by mapping each predicted value onto a tuple that represents an RGB value, and then saves it as a new image in a designated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_predicted(predicted_values, d, newfilename):\n",
    "    n0r_to_color = {5: (4, 233, 231, 1),\n",
    "     10: (1, 159, 244, 1),\n",
    "     15: (3, 0, 244, 1),\n",
    "     20: (2, 253, 2, 1),\n",
    "     25: (1, 197, 1, 1),\n",
    "     30: (0, 142, 0, 1),\n",
    "     35: (253, 248, 2, 1),\n",
    "     40: (229, 188, 0, 1),\n",
    "     45: (253, 149, 0, 1),\n",
    "     50: (253, 0, 0, 1),\n",
    "     55: (212, 0, 0, 1),\n",
    "     65: (248, 0, 253, 1),\n",
    "     70: (152, 84, 198, 1),\n",
    "     75: (253, 253, 253, 1),\n",
    "     0: (0,0,0,0)}\n",
    "    rgba_image_array = []\n",
    "    for value in predicted_values:\n",
    "        rgba_image_array.append(n0r_to_color[value-value%5])\n",
    "    img = Image.new(\"RGBA\", (d, d), color = (0,0,0,0))\n",
    "    img.putdata(rgba_image_array)\n",
    "    img.save(newfilename, transparent = 0)\n",
    "    \n",
    "predicted_filenames = [\"N0R_ABR_1\"]\n",
    "predicted_filepaths = []\n",
    "for predicted_filename in predicted_filenames:\n",
    "    predicted_filepath = \"radar_predicted/\" + predicted_filename + \".gif\"\n",
    "    predicted_filepaths += [predicted_filepath]\n",
    "    save_predicted(predicted_radar, 20, predicted_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image example\n",
    "\n",
    "Here I've compared a predicted image, using models trained over four iterations, with the actual image corresponding with the test dataset, for purposes of illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Predicted N0R at ABR: <img src=\"radar_predicted/N0R_ABR_1.gif\" width=50% height=50% style=\"image-rendering:pixelated\"><br>Actual N0R at ABR: <img src=\"radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ABR/small/ABR_20170303_2241_N0R.gif\" width=50% height=50% style=\"image-rendering:pixelated\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "displayMarkup = 'Predicted {} at {}: <img src=\"{}\" width=50% height=50% style=\"image-rendering:pixelated\">'.format(\"N0R\", \"ABR\", predicted_filepaths[0])\n",
    "Y_test_filepath = \"radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ABR/small/\" + os.listdir(\"radar_archive/radar.weather.gov/ridge/RadarImg/N0R/ABR/small\")[30]\n",
    "# Y_test_filepath = cur_path + \"/small/\" + os.listdir(cur_path+\"/small\")[-2]\n",
    "displayMarkup += '<br>Actual {} at {}: <img src=\"{}\" width=50% height=50% style=\"image-rendering:pixelated\">'.format(\"N0R\", \"ABR\", Y_test_filepath)\n",
    "display.HTML(displayMarkup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating accuracy\n",
    "\n",
    "To create a measure of accuracy the following function calculates both Mean Squared Error (MSE) and Euclidian Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.965, 0.14111165791670083)\n"
     ]
    }
   ],
   "source": [
    "def mse_euclidian_error(predicted, calculated):\n",
    "    from math import sqrt\n",
    "    squared_total_vals = 0.0\n",
    "    length = len(calculated)\n",
    "    for i in range(length):\n",
    "        squared_total_vals += (predicted[i] - calculated[i])**2\n",
    "    mse = squared_total_vals/length\n",
    "    euclidian_distance = sqrt(squared_total_vals)/length\n",
    "    return mse, euclidian_distance\n",
    "\n",
    "im = Image.open(Y_test_filepath)\n",
    "Y_file_vals = translate_n0r(list(im.getdata()), im.getpalette())\n",
    "print(mse_euclidian_error(Y_file_vals, predicted_radar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(mse_euclidian_error(Y_file_vals, Y_file_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1037.3425, 1.6103900924931203)\n"
     ]
    }
   ],
   "source": [
    "random_1 = []\n",
    "random_2 = []\n",
    "for i in range(400):\n",
    "    random_1.append(random.randrange(0,76))\n",
    "    random_2.append(random.randrange(0,76))\n",
    "print(mse_euclidian_error(random_1, random_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing results of different training set sizes\n",
    "\n",
    "The function error_from_num_iterations is all the code we have demonstrated so far collected to return an error rate. The parameter num_iterations specifies the number of rows from each of the stations MPX, DMX, ABR, OAX, and ILX to use in model training. The example below compares the accuracy of five total rows versus ten. It is a small amount, but I felt that I would need greater computing power to be able to scale this very much further.\n",
    "\n",
    "**WARNING: THE FOLLOWING CELL ALWAYS AN TAKES EXTREMELY LONG TIME TO RUN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0.12318684994754919],\n",
       " [2, 0.12234684303242156],\n",
       " [4, 0.12278029157808674],\n",
       " [6, 0.12116620816052634]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def error_from_num_iterations(num_iterations):\n",
    "    to_dataframe, Y_file_vals = import_data([\"MPX\", \"DMX\", \"ABR\", \"OAX\", \"ILX\"], \"N0R\", 30, num_iterations)\n",
    "\n",
    "    # Create labels for the data\n",
    "    df_columns = []\n",
    "    for i in range(30):\n",
    "        for j in range(20):\n",
    "            for k in range(20):\n",
    "                df_columns.append(str(i)+\":\"+str(j+1)+\",\"+str(k+1))\n",
    "\n",
    "    # Convert to Pandas dataframe\n",
    "    df = pd.DataFrame(to_dataframe, columns=df_columns)\n",
    "    df = df._get_numeric_data()\n",
    "\n",
    "    # Train pixel models\n",
    "    pixel_models = []\n",
    "    for i in range(20**2):\n",
    "        Y_train_pixel = pd.DataFrame(Y_file_vals[i])\n",
    "        pixel_models.append(Lasso(alpha=100).fit(df, Y_train_pixel))\n",
    "\n",
    "    X_test, Y_test = import_data([\"LSX\"], \"N0R\", 30, 1)\n",
    "    df_test = pd.DataFrame(X_test, columns=df_columns)\n",
    "    df_test = df_test._get_numeric_data()\n",
    "\n",
    "    predicted_radar = []\n",
    "    for i in range(20**2):\n",
    "        predicted_pixel_Y = pixel_models[i].predict(df)\n",
    "        predicted_radar.append(int(predicted_pixel_Y[0]))\n",
    "\n",
    "    predicted_filenames = [\"N0R_ABR_1\"]\n",
    "    predicted_filepaths = []\n",
    "    for predicted_filename in predicted_filenames:\n",
    "        predicted_filepath = \"radar_predicted/\" + predicted_filename + \".gif\"\n",
    "        predicted_filepaths += [predicted_filepath]\n",
    "        save_predicted(predicted_radar, 20, predicted_filepath)\n",
    "\n",
    "    im = Image.open(Y_test_filepath)\n",
    "    Y_file_vals = translate_n0r(list(im.getdata()), im.getpalette())\n",
    "    mse, euc = mse_euclidian_error(Y_file_vals, predicted_radar)\n",
    "    return euc\n",
    "\n",
    "error_by_iterations = []\n",
    "# Warning: the number of rows you enter as the range will be multiplied by 5! 1 is not a small difference!\n",
    "for i in [1, 2, 4, 6]:\n",
    "    ls = []\n",
    "    ls.append(i)\n",
    "    ls.append(error_from_num_iterations(i))\n",
    "    error_by_iterations.append(ls)\n",
    "error_by_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaton of error rates\n",
    "\n",
    "According to the visualization below, it is easy to see that the error rates of the prediction are decreasing even over elementary increases to the size of the training set. With even more computing power we would be able to see a greater increase in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1176a4a20>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIYZApLUsH8DFNMVhdRNMrAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104aa8048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_x = []\n",
    "plot_y = []\n",
    "for i in range(len(error_by_iterations)):\n",
    "    plot_x.append(error_by_iterations[i][0])\n",
    "    plot_y.append(error_by_iterations[i][1])\n",
    "        \n",
    "plot_x = np.array(plot_x)\n",
    "plot_y = np.array(plot_y)\n",
    "plt.scatter(plot_x, plot_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and future work\n",
    "\n",
    "I found that larger training sizes actually did improve the predictive ability of the model we used. However, the research effort was constrained by the very same issues that hamper NWP prediction techniques at large scale - the availability of computing power.\n",
    "\n",
    "In future research, we can ask questions about the effectiveness of different models in relation to one another, as well as the ability of ML techniques to predict further into the future. It would also be a good idea to migrate the operation to a remote server with greater computing capability, or possibly adapt the project to a parallel computing platform to take advantage of a Beowulf cluster."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
